{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf27566",
   "metadata": {},
   "source": [
    "## FINAL PROJECT: ISM 6562 - BIG DATA FOR BUSINESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d645adf",
   "metadata": {},
   "source": [
    "**Steps for setup:**\n",
    "1. Run in VS Code terminal: pip install numpy pandas matplotlib seaborn ucimlrepo pyspark scikit-learn findspark ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db89d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"330\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#46327e;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#365c8d;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#277f8e;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#1fa187;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#4ac16d;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#a0da39;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.275191, 0.194905, 0.496005),\n",
       " (0.212395, 0.359683, 0.55171),\n",
       " (0.153364, 0.497, 0.557724),\n",
       " (0.122312, 0.633153, 0.530398),\n",
       " (0.288921, 0.758394, 0.428426),\n",
       " (0.626579, 0.854645, 0.223353)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import findspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "sns.color_palette(palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba67651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/01 19:59:42 WARN Utils: Your hostname, Mauricios-MacBook-Pro-4.local resolves to a loopback address: 127.0.0.1; using 10.243.20.248 instead (on interface en0)\n",
      "25/05/01 19:59:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/01 19:59:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"CommunitiesCrime\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ea729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pyspark\n"
     ]
    }
   ],
   "source": [
    "findspark.init() \n",
    "# If you have a SPARK_HOME environment variable set, it might find it automatically\n",
    "spark_path = findspark.find()\n",
    "print(spark_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d0f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "communities_and_crime = fetch_ucirepo(id=183) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = communities_and_crime.data.features \n",
    "y = communities_and_crime.data.targets \n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Convert the merged pandas DataFrame to PySpark DataFrame\n",
    "spark_df = spark.createDataFrame(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
